{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoiding catastrophic interference with dreams (activation maximization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test is performed on MNIST and Fashion-MNIST data.\n",
    "\n",
    "In \"plain\" version, all auxiliary code is removed\n",
    "\n",
    "**Warning**: dreams generation is extremely slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Disable GPU in a case of kernel freezing\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qrfd6FzSLrE2"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist, fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import utils\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import toimage\n",
    "%matplotlib inline \n",
    "import PIL.Image as pil\n",
    "from progressbar import ProgressBar  # pip install progressbar33\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from scipy.special import expit\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IqHMRuH_dk83"
   },
   "outputs": [],
   "source": [
    "# hyperparameters for the main neural network\n",
    "num_epoch = 20\n",
    "num_neur = 400 # number of neurons in hidden layers\n",
    "num_class = 10\n",
    "img_line = 784\n",
    "bsize = 32\n",
    "l2 = 1e-4 # L2 regularization\n",
    "\n",
    "# hyperparamerets for dreams generation\n",
    "nb_dreams = 2000 # number of dreams generated per class\n",
    "# WARNING! Too big llr may result in solver converging to the same local minimum\n",
    "llr = 0.01 # learning rate for dream-generating network\n",
    "ll2 = 0.01 # prior weights distribution\n",
    "min_delta=0.0003 # stop criterion for gradient descend\n",
    "dream_epochs = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5L3LUIi8PDV"
   },
   "outputs": [],
   "source": [
    "# Load training datasets\n",
    "dataset = 1 # '0' or '1' for MNIST or Fashion-MNIST\n",
    "if dataset == 0:\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "else:\n",
    "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZveVc0FdPX6"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, img_line)\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255\n",
    "X_test = X_test.reshape(10000, img_line)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    "\n",
    "Y_train = utils.to_categorical(y_train, 10)\n",
    "Y_test = utils.to_categorical(y_test, 10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(num_neur, input_dim=img_line, activation=\"relu\",kernel_regularizer=regularizers.l2(l2)))\n",
    "model.add(Dense(num_neur, activation=\"relu\",kernel_regularizer=regularizers.l2(l2)))\n",
    "model.add(Dense(num_class, activation=\"softmax\",kernel_regularizer=regularizers.l2(l2)))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(lr=0.001), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training network  on data A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "ezoKvziJdUB4",
    "outputId": "4db84ede-5a94-4eb2-fa5f-212f25ad9165"
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('weights_a.h5'): # if network was trained before\n",
    "    model.load_weights(\"weights_a.h5\") # load weights\n",
    "    score_a = np.load('score_a.npy') # load training history for data A\n",
    "    order_a = np.loadtxt('order_a.txt', dtype=int) # load permutation order of data A\n",
    "    # Restore permitted data A\n",
    "    tr_a = X_train[:,order_a]\n",
    "    ts_a = X_test[:,order_a]\n",
    "else: # train network from begining if not trained before\n",
    "    order_a = np.random.permutation(img_line)\n",
    "    np.savetxt('order_a.txt', order_a, fmt='%d') # save permutation order\n",
    "    tr_a = X_train[:,order_a]\n",
    "    ts_a = X_test[:,order_a]\n",
    "\n",
    "    score_a = np.zeros((num_epoch,2))\n",
    "    history = model.fit(tr_a, Y_train, batch_size=bsize, epochs=num_epoch, validation_data=(ts_a,Y_test), verbose=0)\n",
    "    model.save_weights('weights_a.h5') # save weights for further use\n",
    "    score_a[:,0] = range(num_epoch)\n",
    "    score_a[:,1] = history.history['val_acc']\n",
    "    np.save('score_a', score_a)\n",
    "\n",
    "    plt.plot(score_a[:,0],score_a[:,1])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dreams about data A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the layers in the trained network\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create network for dreams production\n",
    "model_dream = Sequential()\n",
    "model_dream.add(Dense(img_line,input_dim=1,kernel_initializer=\"uniform\",\n",
    "                      kernel_regularizer=regularizers.l2(ll2),activation='sigmoid',use_bias=False))\n",
    "model_dream.add(model)\n",
    "sgd = optimizers.SGD(lr=llr)\n",
    "model_dream.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate dream for a one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping = EarlyStopping(monitor='loss', min_delta=min_delta)\n",
    "# neuron = 9 # output neuron for activation maximization\n",
    "# x_in = np.array([[1]])\n",
    "# y_out = np.zeros((1,num_class))\n",
    "# y_out[0][neuron] = 1\n",
    "# nb_dreams = X_train.shape[0]//num_class # number of dreams per node\n",
    "# weights = np.array([[2*np.random.randn(img_line)]])\n",
    "# model_dream.layers[0].set_weights(weights) # initialize dream with random distribution \n",
    "# history = model_dream.fit(x_in,y_out,batch_size=1,epochs=dream_epochs,verbose=0,shuffle=False,callbacks=[early_stopping])\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create array of dreams starting from random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', min_delta=min_delta)\n",
    "\n",
    "x_in = np.array([[1]])\n",
    "for node in range(num_class): # generate dreams for every output node\n",
    "    y_out = np.zeros((1,num_class))\n",
    "    y_out[0][node] = 1 # create output target\n",
    "    print('Creating dreams for node #%d' % (node))\n",
    "    pbar = ProgressBar(maxval=nb_dreams).start()\n",
    "    dreams = np.zeros((nb_dreams,img_line))\n",
    "    for ind in range(nb_dreams):\n",
    "        weights = np.array([[2*np.random.randn(img_line)]])\n",
    "        model_dream.layers[0].set_weights(weights) # initialize dream with random distribution \n",
    "        model_dream.fit(x_in,y_out,batch_size=1,epochs=dream_epochs,verbose=0,shuffle=False,callbacks=[early_stopping])\n",
    "        dream = expit(model_dream.layers[0].get_weights()[0]) # output of the first layer = input pattern\n",
    "        dreams[ind,:] = dream\n",
    "        pbar.update(ind+1)\n",
    "    pbar.finish()\n",
    "    pickle.dump(dreams, open(\"dream#\"+str(node)+\"_a.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training network on data B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read pickled dreams for data A from a disk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dreams_a = np.zeros((nb_dreams*num_class,img_line)) # array of dreams \n",
    "\n",
    "for node in range(num_class): # load dreams from a disk\n",
    "    dream = pickle.load(open(\"dream#\"+str(node)+\"_a.p\", \"rb\"))\n",
    "    dreams_a[node*nb_dreams:(node+1)*nb_dreams,:] = dream[:nb_dreams,:]\n",
    "\n",
    "# mix classes of dreams\n",
    "order_all = np.random.permutation(dreams_a.shape[0])\n",
    "dreams_a = dreams_a[order_all,:]\n",
    "dreamY_a = model.predict(dreams_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the histogram of output values\n",
    "dreamY_max = np.amax(dreamY_a, axis=1) # take maximum value of every output vector\n",
    "plt.hist(dreamY_max, bins='auto')  \n",
    "plt.title(\"Distribution of maximum activity nodes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot histogram of separate classes\n",
    "# node = 9\n",
    "# dreams1 = pickle.load(open(\"dream#\"+str(node)+\"_a.p\", \"rb\"))\n",
    "# dreamY = model.predict(dreams1)\n",
    "# dreamY_max = dreamY[:,node]\n",
    "# plt.hist(dreamY_max, bins='auto')  \n",
    "# plt.title(\"Distribution of maximum activity nodes\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use data B together with dreams for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "pBrgbxds7cSa",
    "outputId": "b06d9ac3-83b5-41ce-c271-ee7fce0d5a00"
   },
   "outputs": [],
   "source": [
    "# Unfreeze all the layers before training\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "if os.path.isfile('weights_ab.h5'): # if network was trained before\n",
    "    model.load_weights(\"weights_ab.h5\") # load weights\n",
    "    score_ab = np.load('score_ab.npy') # load training history for data A and B\n",
    "    order_b = np.loadtxt('order_b.txt', dtype=int) # load permutation order of data B\n",
    "    # Restore permutted data B\n",
    "    tr_b = X_train[:,order_b]\n",
    "    ts_b = X_test[:,order_b]\n",
    "else: # train network from begining if not trained before\n",
    "    # construct B data\n",
    "    order_b = np.random.permutation(img_line)\n",
    "    np.savetxt('order_b.txt', order_b, fmt='%d') # save permutation order for data B\n",
    "    tr_b = X_train[:,order_b]\n",
    "    ts_b = X_test[:,order_b]\n",
    "\n",
    "    tr_ab = np.concatenate((tr_b, dreams_a), axis=0) # add pseudodata to the training data\n",
    "    Y_ab = np.concatenate((Y_train, dreamY_a), axis=0) # add pseudotargets to the targets\n",
    "\n",
    "    # permute training samples for proper validation set\n",
    "    order_all = np.random.permutation(tr_ab.shape[0])\n",
    "    tr_ab = tr_ab[order_all,:]\n",
    "    Y_ab = Y_ab[order_all,:]\n",
    "\n",
    "    score_ab = np.zeros((num_epoch,3))\n",
    "    pbar = ProgressBar(maxval=num_epoch).start()\n",
    "    for epoch in range(num_epoch):\n",
    "        model.fit(tr_ab, Y_ab, batch_size=bsize, epochs=1, verbose=0)\n",
    "        score1 = model.evaluate(ts_a, Y_test, verbose=0)\n",
    "        score2 = model.evaluate(ts_b, Y_test, verbose=0)\n",
    "        score_ab[epoch,:] = [epoch+num_epoch,score1[1],score2[1]]\n",
    "        pbar.update(epoch+1)\n",
    "    pbar.finish()\n",
    "    model.save_weights('weights_ab.h5') # save weights for further use\n",
    "    np.save('score_ab', score_ab) # save the history of training\n",
    "\n",
    "# plot the accuracy of training\n",
    "plt.plot(np.hstack((score_a[:,0],score_ab[:,0])),np.hstack((score_a[:,1],score_ab[:,1])),label='data A')\n",
    "plt.plot(score_ab[:,0],score_ab[:,2],label='data B')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dreams about data A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the layers in the trained network\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Create network for dreams production\n",
    "model_dream = Sequential()\n",
    "model_dream.add(Dense(img_line,input_dim=1,kernel_initializer=\"uniform\",\n",
    "                      kernel_regularizer=regularizers.l2(ll2),activation='sigmoid',use_bias=False))\n",
    "model_dream.add(model)\n",
    "sgd = optimizers.SGD(lr=llr)\n",
    "model_dream.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate an array of dreams about data A and B starting from a random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', min_delta=min_delta)\n",
    "\n",
    "x_in = np.array([[1]])\n",
    "for node in range(num_class): # generate dreams for every output node\n",
    "    y_out = np.zeros((1,num_class))\n",
    "    y_out[0][node] = 1 # create output target\n",
    "    print('Creating dreams for node #%d' % (node))\n",
    "    pbar = ProgressBar(maxval=nb_dreams).start()\n",
    "    dreams = np.zeros((nb_dreams,img_line))\n",
    "    for ind in range(nb_dreams):\n",
    "        weights = np.array([[2*np.random.randn(img_line)]])\n",
    "        model_dream.layers[0].set_weights(weights) # initialize dream with random distribution \n",
    "        model_dream.fit(x_in,y_out,batch_size=1,epochs=dream_epochs,verbose=0,shuffle=False,callbacks=[early_stopping])\n",
    "        dream = expit(model_dream.layers[0].get_weights()[0]) # output of the first layer = input pattern\n",
    "        dreams[ind,:] = dream\n",
    "        pbar.update(ind+1)\n",
    "    pbar.finish()\n",
    "    pickle.dump(dreams, open(\"dream#\"+str(node)+\"_ab.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training network on data C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dreams from a disk\n",
    "dreams_ab = np.empty((0,img_line),np.float32)\n",
    "for node in range(num_class): # load dreams from a disk\n",
    "    dream = pickle.load(open(\"dream#\"+str(node)+\"_ab.p\", \"rb\"))\n",
    "    dreams_ab = np.vstack((dreams_ab,dream))\n",
    "\n",
    "# mix classes of dreams\n",
    "order_all = np.random.permutation(dreams_ab.shape[0])\n",
    "dreams_ab = dreams_ab[order_all,:]\n",
    "dreamsY_ab = model.predict(dreams_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the histogram of output values\n",
    "dreamY_max = np.amax(dreamsY_ab, axis=1) # take maximum value of every output vector\n",
    "plt.hist(dreamY_max, bins='auto')  \n",
    "plt.title(\"Distribution of maximum activity nodes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "colab_type": "code",
    "id": "9ZF-RkFY7vDS",
    "outputId": "cd8585f5-ee9e-4d80-8c42-74647e5372e1"
   },
   "outputs": [],
   "source": [
    "# Unfreeze all the layers before training\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# create dataset C\n",
    "order_c = np.random.permutation(img_line)\n",
    "tr_c = X_train[:,order_c]\n",
    "ts_c = X_test[:,order_c]\n",
    "\n",
    "# add pseudodata to the training data\n",
    "tr_abc = np.concatenate((tr_c, dreams_ab), axis=0) \n",
    "Y_abc = np.concatenate((Y_train, dreamsY_ab), axis=0)\n",
    "# permute training samples for proper validation set\n",
    "order_all = np.random.permutation(tr_abc.shape[0])\n",
    "tr_abc = tr_abc[order_all,:]\n",
    "Y_abc = Y_abc[order_all,:]\n",
    "\n",
    "score_abc = np.zeros((num_epoch,4))\n",
    "pbar = ProgressBar(maxval=num_epoch).start()\n",
    "for epoch in range(num_epoch):\n",
    "    model.fit(tr_abc, Y_abc, batch_size=bsize, epochs=1, verbose=0)\n",
    "    score1 = model.evaluate(ts_a, Y_test, verbose=0)\n",
    "    score2 = model.evaluate(ts_b, Y_test, verbose=0)\n",
    "    score3 = model.evaluate(ts_c, Y_test, verbose=0)\n",
    "    score_abc[epoch,:] = [epoch+num_epoch*2,score1[1],score2[1],score3[1]]\n",
    "    pbar.update(epoch+1)\n",
    "pbar.finish()\n",
    "\n",
    "#plot training history\n",
    "plt.plot(np.concatenate((score_a[:,0],score_ab[:,0],score_abc[:,0]),axis=0),\n",
    "         np.concatenate((score_a[:,1],score_ab[:,1],score_abc[:,1]),axis=0),label='data A')\n",
    "plt.plot(np.hstack((score_ab[:,0],score_abc[:,0])),np.hstack((score_ab[:,2],score_abc[:,2])),label='data B')\n",
    "plt.plot(score_abc[:,0],score_abc[:,3],label='data C')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history for further processing\n",
    "#np.savez('Dreams_0',score_a=score_a,score_ab=score_ab,score_abc=score_abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ABC_Mnist_13.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
